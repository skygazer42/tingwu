# ============================================================
# TingWu 语音转写服务配置文件
# ============================================================
# ------------------------------------------------------------
# 服务配置
# ------------------------------------------------------------
# 服务监听地址
HOST=0.0.0.0
# 服务端口
PORT=8000
# 调试模式 (生产环境请设为 false)
DEBUG=false

# ------------------------------------------------------------
# （可选）Docker 容器内下载模型用代理
# ------------------------------------------------------------
# 说明：
# - 如果你本机需要代理才能访问 HuggingFace/ModelScope，容器内也需要代理环境变量。
# - 注意：容器内的 127.0.0.1 不是宿主机；在 macOS/Windows Docker Desktop 通常用 host.docker.internal。
HTTP_PROXY=
HTTPS_PROXY=
ALL_PROXY=
NO_PROXY=localhost,127.0.0.1,::1
http_proxy=
https_proxy=
all_proxy=
no_proxy=localhost,127.0.0.1,::1

# ------------------------------------------------------------
# 多模型容器端口（docker-compose.models.yml 用）
# ------------------------------------------------------------
# 说明：每个模型/后端单独一个 TingWu 容器，API 路径一致，端口不同（按需启动）
# PyTorch Paraformer (GPU)
PORT_PYTORCH=8101
# ONNX (CPU)
PORT_ONNX=8102
# SenseVoice (GPU)
PORT_SENSEVOICE=8103
# GGUF (CPU)
PORT_GGUF=8104
# Whisper (GPU)
PORT_WHISPER=8105
# External diarizer (pyannote)
PORT_DIARIZER=8300
# Remote 模型服务端口（仅用于调试暴露；TingWu 内部走 service name）
PORT_QWEN3_ASR=9001
PORT_VIBEVOICE_ASR=9002
# TingWu 远程模型包装后的统一 API 端口
PORT_TINGWU_ROUTER=8200
PORT_TINGWU_QWEN3=8201
PORT_TINGWU_VIBEVOICE=8202

# VibeVoice vLLM 容器需要挂载本地 VibeVoice 仓库目录（包含 vllm_plugin）
VIBEVOICE_REPO_PATH=/path/to/VibeVoice

# Remote 模型容器可选参数（docker-compose.models.yml 用）
QWEN3_MODEL_ID=Qwen/Qwen3-ASR-1.7B
VIBEVOICE_MODEL_ID=microsoft/VibeVoice-ASR
VIBEVOICE_SERVED_MODEL_NAME=vibevoice

# External diarizer (pyannote) 需要 HuggingFace Token（部分模型受限，需要在 HF 上申请访问）
# 将该 token 传给容器用于自动下载模型权重，并缓存到 huggingface-cache volume（不会把权重打进镜像）。
HF_TOKEN=
DIARIZER_MODEL=pyannote/speaker-diarization-3.1
# 推荐：容器启动时预热（自动下载/加载模型，避免首次请求超时）
DIARIZER_WARMUP_ON_STARTUP=true

# 可选：如果你大致知道会议人数，设置 speaker 数范围能提升分离稳定性
# 三选一即可（优先级：NUM_SPEAKERS > MIN/MAX）
DIARIZER_NUM_SPEAKERS=
DIARIZER_MIN_SPEAKERS=
DIARIZER_MAX_SPEAKERS=

# ------------------------------------------------------------
# 设备配置
# ------------------------------------------------------------
# 计算设备: cuda | cpu
DEVICE=cuda
# GPU 数量
NGPU=1
# CPU 核心数
NCPU=4

# ------------------------------------------------------------
# ASR 后端配置
# ------------------------------------------------------------
# ASR 后端类型: pytorch | onnx | sensevoice | gguf | qwen3 | vibevoice | router | whisper
# - pytorch: FunASR PyTorch 后端 (默认，功能最全)
# - onnx: FunASR ONNX 后端 (更快，需要 funasr-onnx)
# - sensevoice: SenseVoice 后端 (阿里达摩院，多语言)
# - gguf: FunASR-Nano GGUF 后端 (轻量级，需要 llama.cpp)
ASR_BACKEND=pytorch

# FunASR 模型配置 (PyTorch 后端)
ASR_MODEL=paraformer-zh
ASR_MODEL_ONLINE=paraformer-zh-streaming
VAD_MODEL=fsmn-vad
PUNC_MODEL=ct-punc-c
SPK_MODEL=cam++

# VAD 参数
# VAD 单段最大时长 (毫秒)
VAD_MAX_SEGMENT_MS=60000
# 语音/噪声阈值 (0-1)
VAD_SPEECH_NOISE_THRES=0.8

# ONNX 后端配置
# 启用 INT8 量化
ONNX_QUANTIZE=true
# ONNX 推理线程数
ONNX_INTRA_THREADS=4
# ONNX 并行操作数
ONNX_INTER_THREADS=1

# SenseVoice 后端配置
SENSEVOICE_MODEL=iic/SenseVoiceSmall
SENSEVOICE_LANGUAGE=zh

# Whisper 后端配置 (openai-whisper)
WHISPER_MODEL=large
# 可选：指定语言（留空/删除则自动检测）
WHISPER_LANGUAGE=zh
# 可选：模型权重下载/缓存目录（建议在 /app/data 下，挂载后可复用）
WHISPER_DOWNLOAD_ROOT=/app/data/models/whisper

# GGUF 后端配置 (需要下载 FunASR-Nano 模型)
GGUF_ENCODER_PATH=models/Fun-ASR-Nano-Encoder-Adaptor.fp32.onnx
GGUF_CTC_PATH=models/Fun-ASR-Nano-CTC.int8.onnx
GGUF_DECODER_PATH=models/Fun-ASR-Nano-Decoder.q8_0.gguf
GGUF_TOKENS_PATH=models/tokens.txt
# llama.cpp 动态库目录
GGUF_LIB_DIR=models/bin

# 模型预热配置
# 启动时预热模型 (首次请求更快)
WARMUP_ON_STARTUP=true
# 预热音频时长 (秒)
WARMUP_AUDIO_DURATION=1.0

# ------------------------------------------------------------
# Remote ASR 后端 (vLLM OpenAI-compatible)
# ------------------------------------------------------------
# Qwen3-ASR (OpenAI transcription API)
QWEN3_ASR_BASE_URL=http://localhost:9001
QWEN3_ASR_MODEL=Qwen/Qwen3-ASR-1.7B
QWEN3_ASR_API_KEY=EMPTY
QWEN3_ASR_TIMEOUT_S=60

# VibeVoice-ASR (OpenAI transcription API; optional chat-completions fallback)
VIBEVOICE_ASR_BASE_URL=http://localhost:9002
VIBEVOICE_ASR_MODEL=vibevoice
VIBEVOICE_ASR_API_KEY=EMPTY
VIBEVOICE_ASR_TIMEOUT_S=600
VIBEVOICE_ASR_USE_CHAT_COMPLETIONS_FALLBACK=true

# Router backend: auto-select between qwen3 and vibevoice
ROUTER_LONG_AUDIO_THRESHOLD_S=60
ROUTER_FORCE_VIBEVOICE_WHEN_WITH_SPEAKER=true
ROUTER_SHORT_BACKEND=qwen3
ROUTER_LONG_BACKEND=vibevoice

# ------------------------------------------------------------

# 热词配置
# ------------------------------------------------------------
# 热词文件路径 (相对于 data/hotwords/)
HOTWORDS_FILE=hotwords.txt
# 上下文热词文件路径 (相对于 data/hotwords/)，仅用于注入提示，不强制替换
HOTWORDS_CONTEXT_FILE=hotwords-context.txt
# 热词匹配阈值 (0-1，越高越严格)
HOTWORDS_THRESHOLD=0.85
# 热词前向注入 (传递给 ASR 模型)
HOTWORD_INJECTION_ENABLE=true
# 最大注入热词数
HOTWORD_INJECTION_MAX=50
# 热词文件热加载 (修改后自动重载)
HOTWORD_WATCH_ENABLE=true
# 热加载防抖秒数
HOTWORD_WATCH_DEBOUNCE=3.0
# 使用 FAISS 向量索引 (大规模热词加速)
HOTWORD_USE_FAISS=false
# FAISS 索引类型: IVFFlat | HNSW
HOTWORD_FAISS_INDEX_TYPE=IVFFlat

# ------------------------------------------------------------
# 说话人 / 会议转写输出配置
# ------------------------------------------------------------
# 说话人标签风格: zh=说话人甲/乙/丙, numeric=说话人1/2/3
SPEAKER_LABEL_STYLE=zh
# 合并同一说话人的连续句子为“turn/段落”
SPEAKER_TURN_MERGE_ENABLE=true
# 两句之间间隔小于该值 (ms) 则合并为同一 turn
SPEAKER_TURN_MERGE_GAP_MS=800
# turn 最少字符数（避免生成特别短的碎片段落）
SPEAKER_TURN_MERGE_MIN_CHARS=1
# 后端不支持说话人识别时是否严格报错（避免静默回退到其它模型）
SPEAKER_STRICT_BACKEND=true
# 新版（优先于 SPEAKER_STRICT_BACKEND）：后端不支持说话人识别时的行为
# - error: 直接报错（HTTP 400）
# - fallback: 回退到 PyTorch 后端（可能违背“端口=模型”的预期）
# - ignore: 忽略说话人（按 with_speaker=false 处理，适合多端口部署）
SPEAKER_UNSUPPORTED_BEHAVIOR=ignore

# Speaker fallback diarization（辅助说话人分离，默认关闭）
# 当当前后端不支持说话人识别（例如 Qwen3-ASR），但你希望仍然输出说话人1/2/3...：
# - 启用该功能会额外调用一个“辅助 TingWu 服务”（通常是 tingwu-pytorch）
# - 失败会自动回退到普通转写（ignore）
SPEAKER_FALLBACK_DIARIZATION_ENABLE=false
SPEAKER_FALLBACK_DIARIZATION_BASE_URL=http://tingwu-pytorch:8000
SPEAKER_FALLBACK_DIARIZATION_TIMEOUT_S=30
# 限制单个说话人 turn 的最大时长（避免 Qwen3 这类远程服务超时）
SPEAKER_FALLBACK_MAX_TURN_DURATION_S=25
# 限制最大 turn 数（避免极端碎片化导致大量请求）
SPEAKER_FALLBACK_MAX_TURNS=200

# Speaker external diarizer（外部说话人分离服务，pyannote；默认关闭）
# 当你希望“任意后端（包括 Qwen3-ASR / Whisper）都输出 说话人1/2/3...”：
# - 启用该功能后，TingWu 会先调用 tingwu-diarizer 获取分段，再按 turn 切片转写
# - diarizer 失败：若后端原生支持 speaker 则回退原生；否则自动忽略 speaker（不硬报错）
SPEAKER_EXTERNAL_DIARIZER_ENABLE=false
SPEAKER_EXTERNAL_DIARIZER_BASE_URL=http://tingwu-diarizer:8000
SPEAKER_EXTERNAL_DIARIZER_TIMEOUT_S=60
SPEAKER_EXTERNAL_DIARIZER_MAX_TURN_DURATION_S=25
SPEAKER_EXTERNAL_DIARIZER_MAX_TURNS=200

# ------------------------------------------------------------
# LLM 润色配置
# ------------------------------------------------------------
# 启用 LLM 润色
LLM_ENABLE=true
# LLM 模型名称
LLM_MODEL=deepseek-chat
# LLM API 地址
LLM_BASE_URL=https://api.deepseek.com/v1
# LLM API Key (OpenAI 兼容接口需要，Ollama 留空)
LLM_API_KEY=
# LLM 后端类型: auto | ollama | openai | vllm
# - auto: 根据 URL 自动检测 (11434=ollama, 8000=vllm, 其他=openai)
# - ollama: 本地 Ollama 服务
# - openai: OpenAI 兼容 API (OpenAI, DeepSeek, 通义千问, Moonshot 等)
# - vllm: vLLM 高吞吐推理服务
LLM_BACKEND=auto
# LLM 角色: default | translator | code | corrector
LLM_ROLE=corrector
# 上下文句子数 (用于多句润色)
LLM_CONTEXT_SENTENCES=1
# 全文纠错模式
LLM_FULLTEXT_ENABLE=false
# 全文最大字数
LLM_FULLTEXT_MAX_CHARS=2000
# 批量润色句子数
LLM_BATCH_SIZE=5
# LLM 上下文 token 限制
LLM_MAX_TOKENS=4096
# LLM 响应缓存
LLM_CACHE_ENABLE=true
# 缓存大小
LLM_CACHE_SIZE=1000
# 缓存 TTL (秒)
LLM_CACHE_TTL=3600

# ------------------------------------------------------------
# 通用文本纠错配置 (pycorrector)
# ------------------------------------------------------------
# 启用通用文本纠错
TEXT_CORRECT_ENABLE=true
# 纠错后端: kenlm | macbert
TEXT_CORRECT_BACKEND=kenlm
# 纠错设备: cpu | cuda (仅 macbert)
TEXT_CORRECT_DEVICE=cpu

# 置信度过滤
# 置信度阈值 (0=禁用)
CONFIDENCE_THRESHOLD=0.0
# 低置信度回退策略: pycorrector | llm
CONFIDENCE_FALLBACK=pycorrector

# ------------------------------------------------------------
# 文本后处理配置
# ------------------------------------------------------------
# 填充词移除 (如 "呃"、"那个"、"就是说")
FILLER_REMOVE_ENABLE=true
# 激进模式移除更多填充词
FILLER_AGGRESSIVE=false
# 全角字符归一化 (ＡＢＣＤ → ABCD)
QJ2BJ_ENABLE=true
# 中文数字格式化 (如 "三百五十" → "350")
ITN_ENABLE=true
# 儿化移除 (如 "那边儿" → "那边")
ITN_ERHUA_REMOVE=true
# 中英文间距 (如 "AI技术" → "AI 技术")
SPACING_CJK_ASCII_ENABLE=false
# 口述标点指令（dictation）：在句首/句末解析 “逗号/句号/问号/感叹号/回车/换行” 等
SPOKEN_PUNC_ENABLE=false
# 英文缩写合并：A I -> AI, V S Code -> VS Code
ACRONYM_MERGE_ENABLE=false
# 繁简转换
ZH_CONVERT_ENABLE=true
# 繁简转换目标: zh-hans | zh-hant | zh-tw | zh-hk
ZH_CONVERT_LOCALE=zh-hans
# 标点转换 (全角→半角)
PUNC_CONVERT_ENABLE=true
# 标点后添加空格
PUNC_ADD_SPACE=true
# 独立标点恢复 (FunASR ct-punc)
PUNC_RESTORE_ENABLE=true
# 标点恢复模型
PUNC_RESTORE_MODEL=ct-punc-c
# 标点智能合并
PUNC_MERGE_ENABLE=false
# 末尾标点移除 (用于实时转写场景)
TRASH_PUNC_ENABLE=false
# 要移除的末尾标点字符
TRASH_PUNC_CHARS=，。,.

# 纠错管线编排 (按顺序执行，逗号分隔)
# 可用步骤: hotword, rules, pycorrector, post_process
CORRECTION_PIPELINE=hotword,rules,pycorrector,post_process

# ------------------------------------------------------------
# WebSocket 配置
# ------------------------------------------------------------
# 音频块大小 (字节，600ms @ 16kHz = 9600)
WS_CHUNK_SIZE=9600
# 在线识别间隔 (每 N 个块执行一次)
WS_CHUNK_INTERVAL=10
# 启用 WebSocket 压缩
WS_COMPRESSION=true
# 心跳间隔 (秒)
WS_HEARTBEAT_INTERVAL=30
# 心跳超时 (秒)
WS_HEARTBEAT_TIMEOUT=60

# ------------------------------------------------------------
# 音频预处理配置
# ------------------------------------------------------------
# 音量归一化
AUDIO_NORMALIZE_ENABLE=true
# 目标电平 (dB)
AUDIO_NORMALIZE_TARGET_DB=-20.0
# 静音裁剪
AUDIO_TRIM_SILENCE_ENABLE=false
# 静音阈值 (dB)
AUDIO_SILENCE_THRESHOLD_DB=-40.0
# 降噪开关
AUDIO_DENOISE_ENABLE=false
# 降噪强度 (0-1)
AUDIO_DENOISE_PROP=0.8
# 降噪后端: noisereduce | deepfilter | deepfilter3
AUDIO_DENOISE_BACKEND=noisereduce
# 人声分离开关
AUDIO_VOCAL_SEPARATE_ENABLE=false
# 人声分离模型
AUDIO_VOCAL_SEPARATE_MODEL=htdemucs
# 自适应预处理 (根据 SNR 智能选择)
AUDIO_ADAPTIVE_PREPROCESS=false
# SNR 阈值 (低于此值启用降噪)
AUDIO_SNR_THRESHOLD=20.0

# ------------------------------------------------------------
# 流式文本去重配置
# ------------------------------------------------------------
# 启用流式去重
STREAM_DEDUP_ENABLE=true
# 重叠检查字符数
STREAM_DEDUP_OVERLAP=5
# 模糊匹配容差
STREAM_DEDUP_TOLERANCE=1
